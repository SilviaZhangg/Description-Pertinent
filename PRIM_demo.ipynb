{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PRIM_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpAIBuiitroG"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jT9sUoSDaZe"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Nov 12 14:57:47 2020\n",
        "\n",
        "@author: yuhanzhang\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "yago_site = \"https://yago-knowledge.org/sparql/query\"\n",
        "yago_code_part1 = '''PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "select ?property_name ?value_name\n",
        "(count(?city) as ?cnt)\n",
        "where {\n",
        "        <http://yago-knowledge.org/resource/'''\n",
        "yago_code_part2 =  '''> ?property ?valueOrObject .\n",
        "       ?city ?property ?valueOrObject.\n",
        "   \t\t?property rdfs:label ?property_name.\n",
        " \t ?valueOrObject rdfs:label ?value_name.\n",
        "  \tfilter(lang(?value_name) = 'en').\n",
        "      } \n",
        "group by?property_name ?value_name\n",
        "HAVING (?cnt > 1)\n",
        "'''\n",
        "\n",
        "\n",
        "yago_inversecode_part1 = '''\n",
        "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "select  ?property_name ?un_name\n",
        "#(group_concat(?un_name; separator = ';') as ?members)\n",
        "#(count(?un) as ?cnt)\n",
        "where {\n",
        "       ?un  ?property <http://yago-knowledge.org/resource/'''\n",
        "yago_inversecode_part2 = '''> .\n",
        "       ?property rdfs:label ?property_name.\n",
        "       ?un rdfs:label ?un_name.\n",
        "       filter(lang(?un_name) = 'en').\n",
        "\n",
        "      } \n",
        "#group by ?property_name\n",
        "'''\n",
        "\n",
        "yago_query_country = '''\n",
        "PREFIX schema: <http://schema.org/>\n",
        "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "                    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "                    select  ?itemLabel \n",
        "(group_concat(?name_orgranization; separator = ';') as ?memberOf)\n",
        "                    where {\n",
        "                            ?country rdf:type schema:Country.\n",
        "  \t\t\t\t\t\t\t?country rdfs:label ?itemLabel.\n",
        "  \t\t\t\t\t\t\tfilter ( lang(?name_country) = 'en').\n",
        "\t\t\t\t\t\t\t?country schema:memberOf ?member.\n",
        "  ?member rdfs:label ?name_orgranization.\n",
        "  filter(lang(?name_orgranization)='en').\n",
        "                            } \n",
        "group by ?itemLabel\n",
        "limit 50\n",
        "'''\n",
        "\n",
        "yago_country_properties = '''\n",
        "\n",
        "'''                    \n",
        "                    \n",
        "stopwords = ['image', '2000/01/rdf-schema#comment','2000/01/rdf-schema#label','alternateName', 'sameAs', 'url']\n",
        "             \n",
        "conceptnet_site_basic1 = 'http://api.conceptnet.io/c/en/'\n",
        "conceptnet_site_basic2 = '?filter=/c/en'\n",
        "\n",
        "conceptnet_site_related1 = 'http://api.conceptnet.io/related/c/en/'\n",
        "conceptnet_site_related2 = '?filter='\n",
        "\n",
        "conceptnet_site_relation1 = 'http://api.conceptnet.io/relatedness?node1=/c/en/'\n",
        "conceptnet_site_relation2 = '&node2=/c/en/'\n",
        "\n",
        "dbpedia_site = \"http://dbpedia.org/sparql\"\n",
        "dbpedia_code_part1 = \"\"\"\n",
        "                        select ?un ?a where{\n",
        "                        \n",
        "                                ?un rdf:type <http://dbpedia.org/ontology/City>.\n",
        "                                ?un <http://dbpedia.org/ontology/country> <http://dbpedia.org/resource/China>.\n",
        "                                ?un <http://dbpedia.org/ontology/\"\"\"\n",
        "dbpedia_code_part2 = \"\"\"> ?a.\n",
        "                                }\n",
        "                        \"\"\"\n",
        "\n",
        "wikidata_query_site = \"https://query.wikidata.org/sparql\"\n",
        "wikidata_data_site = 'https://en.wikipedia.org/w/api.php?action=query&prop=pageprops&ppprop=wikibase_item&redirects=1&titles=Elvis_Presley'\n",
        "wikidata_query_city = '''\n",
        "SELECT distinct ?item ?itemLabel ?length_in_m ?area_in_m2 ?population ?itemdesc\n",
        "WHERE\n",
        "{\n",
        "  ?item          wdt:P31/wdt:P279*           wd:Q515.    # city\n",
        "  ?item          p:P2044                     ?stmnode.    # sealevel\n",
        "  ?stmnode       psv:P2044                   ?valuenode.\n",
        "  ?valuenode     wikibase:quantityAmount     ?length.\n",
        "  ?valuenode     wikibase:quantityUnit       ?unit.\n",
        "  \n",
        "  ?item          p:P2046                     ?area.\n",
        "  ?area          psv:P2046                   ?areavalue.\n",
        "  ?areavalue     wikibase:quantityAmount     ?areabig.\n",
        "  ?areavalue     wikibase:quantityUnit       ?unitarea.\n",
        "\n",
        "  ?item          wdt:P1082                   ?population.\n",
        "  \n",
        "  ?item schema:description ?itemdesc.\n",
        "  FILTER(LANG(?itemdesc) = \"en\")\n",
        "\n",
        "  # conversion to SI unit\n",
        "  ?unit          p:P2370                 ?unitstmnode.   # conversion to SI unit\n",
        "  ?unitstmnode   psv:P2370               ?unitvaluenode. \n",
        "  ?unitvaluenode wikibase:quantityAmount ?conversion.\n",
        "  ?unitvaluenode wikibase:quantityUnit   wd:Q11573.      # meter\n",
        "  \n",
        "  BIND(?length * ?conversion AS ?length_in_m).\n",
        "  \n",
        "  ?unitarea          p:P2370       ?unitareastmode.\n",
        "  ?unitareastmode    psv:P2370     ?unitareavaluenode.\n",
        "  ?unitareavaluenode wikibase:quantityAmount ?conversionarea.\n",
        "  ?unitareavaluenode wikibase:quantityUnit  wd:Q25343.\n",
        "  \n",
        "   BIND(?areabig * ?conversionarea AS ?area_in_m2).\n",
        "  \n",
        "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
        "} \n",
        "    '''\n",
        "wikidata_city_properties = ['area','population','sea_level']\n",
        "\n",
        "\n",
        "google_site_part1 = \"https://www.google.com/search?q=\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fcj5Z7GpDhCy",
        "outputId": "41239a0b-e8d2-43d2-85b7-f04e82e59f7d"
      },
      "source": [
        "!pip install SPARQLWrapper"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SPARQLWrapper\n",
            "  Downloading https://files.pythonhosted.org/packages/00/9b/443fbe06996c080ee9c1f01b04e2f683b2b07e149905f33a2397ee3b80a2/SPARQLWrapper-1.8.5-py3-none-any.whl\n",
            "Collecting rdflib>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 10.7MB/s \n",
            "\u001b[?25hCollecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib>=4.0->SPARQLWrapper) (1.15.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib>=4.0->SPARQLWrapper) (2.4.7)\n",
            "Installing collected packages: isodate, rdflib, SPARQLWrapper\n",
            "Successfully installed SPARQLWrapper-1.8.5 isodate-0.6.0 rdflib-5.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbEhNzHtDZR_",
        "outputId": "30b2626e-790f-4349-8efb-5915bec85b1b"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sat Dec 12 17:03:24 2020\n",
        "\n",
        "@author: yuhanzhang\n",
        "\n",
        "This python file provides methods to generate pertinent descriptions based on knowledge bases.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "import requests\n",
        "import pandas as pd\n",
        "import sys\n",
        "import re\n",
        "import math\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "class SparQL:\n",
        "    '''\n",
        "    This class realizes those functions: \n",
        "        1.send queries to knowledge bases and get result; \n",
        "        2.organize information in pandas data frame\n",
        "        3.calculate complexity of information\n",
        "        4.generate pertinent descriptions from complexity\n",
        "        \n",
        "    objects in this class:\n",
        "        1.searching_objet: the item one interested in, in format str\n",
        "        2.query: query to send to obtain normal properties, in format str\n",
        "        3.inverse_query: query to send to obtain incoming properties, in format str\n",
        "        4.endpoint: knowledge base's endpoint, in format str\n",
        "    '''\n",
        "\n",
        "    \n",
        "    def get_results(self, inverse):\n",
        "        '''\n",
        "        Get results from knowledge bases.\n",
        "        ----------\n",
        "        input: self\n",
        "               Boolean value: inverse. If inverse = Flase, get results of normal properties; else, get results of incoming properties\n",
        "        ----------\n",
        "        output: a dictionary with unorganized information\n",
        "        '''\n",
        "        user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
        "        # TODO adjust user agent; see https://w.wiki/CX6\n",
        "        sparql = SPARQLWrapper(self.endpoint, agent=user_agent)\n",
        "        \n",
        "        # To collect incoming properties\n",
        "        if inverse:\n",
        "            sparql.setQuery(self.inverse_query)\n",
        "        # To collect normal properties\n",
        "        else:\n",
        "            sparql.setQuery(self.query)\n",
        "        sparql.setReturnFormat(JSON)       \n",
        "        return sparql.query().convert()\n",
        "    \n",
        "    def wikidata_query(self, inverse):\n",
        "        '''\n",
        "        Get organized information\n",
        "        ----------\n",
        "        input: self\n",
        "               Boolean value: inverse. If inverse = Flase, get results of normal properties; else, get results of incoming properties\n",
        "        ----------\n",
        "        output: a dataframe with organized information\n",
        "        '''\n",
        "        results = self.get_results(inverse)\n",
        "        if len(results['results']['bindings']) > 0:\n",
        "            keys = list(results['results']['bindings'][0].keys())\n",
        "        else:\n",
        "            proto = []\n",
        "            df = pd.DataFrame(proto)\n",
        "            return df\n",
        "        prototype = []\n",
        "        flag = 0\n",
        "        for item in results['results']['bindings']:\n",
        "            #if self.searching_objet != item['value_name']['value']:\n",
        "            if True:\n",
        "              dictionary = {}\n",
        "              for key in keys:\n",
        "                  if item[key]['value'] in self.searching_objet:\n",
        "                      flag = -1\n",
        "                  try:\n",
        "                      dictionary[key] = float(item[key]['value'])\n",
        "                  except:\n",
        "                      dictionary[key] = item[key]['value']\n",
        "              if flag != -1:        \n",
        "                  prototype.append(dictionary)\n",
        "\n",
        "        df = pd.DataFrame(prototype)\n",
        "        return df\n",
        "    \n",
        "    def wiki_contrast(self):\n",
        "        results = self.get_results(False)\n",
        "        cities = []\n",
        "\n",
        "        for item in results['results']['bindings']:\n",
        "            cities.append({\n",
        "                    #'area': item['area']['value'],\n",
        "                    'itemLabel': item['itemLabel']['value'],\n",
        "                    'itemdesc': item['itemdesc']['value'],\n",
        "                    'population': float(item['population']['value']),\n",
        "                    'area': float(item['area_in_m2']['value']),\n",
        "                    'sea_level': float(item['length_in_m']['value'])\n",
        "                    })\n",
        "        df = pd.DataFrame(cities)\n",
        "        return df\n",
        "    \n",
        "    def find_hitsnumber(self,searching_item):\n",
        "        '''\n",
        "        Get hits number of one item in Google\n",
        "        ----------\n",
        "        input: searching_item(str): The item we want to search\n",
        "        ----------\n",
        "        output: hits number (int)\n",
        "        '''        \n",
        "        \n",
        "        headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:23.0) Gecko/20100101 Firefox/23.0'}\n",
        "        # Accroding to the rule of URL of Google, the space will be replaced by the sign + in the url.\n",
        "        searching = re.sub('\\ ','+',searching_item)\n",
        "        # For users from different countries, we use different urls\n",
        "        if self.language == 'en': # English speakers\n",
        "            response = requests.get(\"https://www.google.com/search?q=\\\"\"+searching+\"\\\"\", headers = headers)\n",
        "        elif self.language == 'fr': # French\n",
        "            #response = requests.get(\"https://www.google.com/search?q=\"+searching+\"&hl=fr\", headers = headers)\n",
        "            response = requests.get(\"https://www.google.fr/search?q=\\\"\"+searching+\"\\\"&lr=lang_fr\", headers = headers)\n",
        "        elif self.language == 'cn': # Chinese\n",
        "            #response = requests.get(\"https://www.google.com.hk/search?q=\"+searching+\"&lr=lang_zh-CN\", headers = headers)\n",
        "            response = requests.get(\"https://www.google.com.hk/search?q=\\\"\"+searching+\"\\\"&lr=lang_zh-CN\", headers = headers)\n",
        "        \n",
        "        time1 = time.time()\n",
        "        res = response.text\n",
        "        soup = BeautifulSoup(res, \"lxml\")\n",
        "        time2 = time.time()\n",
        "        #print(time2-time1)\n",
        "        str_hits = soup.find_all(attrs={'id':'result-stats'})\n",
        "        l= re.split(r'[\\s\\,]+',str(str_hits))\n",
        "        hits = ''\n",
        "        for i in range(len(l[2:-5])):\n",
        "            hits += l[2:-5][i]\n",
        "        try:\n",
        "            hit_number = int(hits)\n",
        "        except:\n",
        "            hit_number = 0\n",
        "        #print(str_hits)\n",
        "        return hit_number\n",
        "\n",
        "    def relatedness_conceptnet(self, item1, item2):\n",
        "        '''\n",
        "        Get relatedness between two items\n",
        "        ----------\n",
        "        input: item1, item2\n",
        "        ----------\n",
        "        output: the relatedness calculated based on ConceptNet, which is a cosine similarity\n",
        "        '''\n",
        "        try:\n",
        "            i1 = item1.lower()\n",
        "            i2 = item2.lower()\n",
        "        except:\n",
        "            return 0\n",
        "        sujet1 = re.sub('\\ ','_',i1)\n",
        "        sujet2 = re.sub('\\ ','_',i2)\n",
        "        try:\n",
        "          response = requests.get('http://api.conceptnet.io/relatedness?node1=/c/en/'+sujet1+'&node2=/c/en/'+sujet2)\n",
        "          obj = response.json()\n",
        "          relatedness = abs(obj['value'])\n",
        "        except:\n",
        "          relatedness = 0\n",
        "        return relatedness\n",
        "    \n",
        "\n",
        "    \n",
        "    def calculate_complexity_1(self, context):\n",
        "        '''\n",
        "        Get complexity of normal properties\n",
        "        ------------\n",
        "        input: context (list)\n",
        "        ------------\n",
        "        output: complexity (list), data\n",
        "        \n",
        "        ------------\n",
        "        Here we calculate the conditional complexity. We apply the chain rule to calculate the complexity:\n",
        "            Complexity(A, value) = Complexity(A|value) + Complexity(value)\n",
        "            For example, if one description is: China is a member of G20, then value is G20, A is China.\n",
        "            Complexity(China,G20) = Complexity(China|G20) + Complexity(G20), \n",
        "            Since there are 20 members in G20, thus, when G20 is known, Find China is like find one element in a list of 20 elements\n",
        "            As a result, Complexity(China|G20) = log2(20)\n",
        "        What's more, Complexity(value) could be calculated by using knowledge base or only context, here we use the number of hits on Google.\n",
        "        Since the cost of using knowledge base is more expensive, we give it 10 more bits for its complexity.\n",
        "        '''\n",
        "        df = self.wikidata_query(False)\n",
        "        if len(df) == 0:\n",
        "            return False, df\n",
        "        complexity_value = []\n",
        "        relatednesses = []\n",
        "        contexte = np.array(context)\n",
        "        lllll = np.zeros(len(df))\n",
        "        for i in range(len(df)):\n",
        "            if df['value_name'][i] not in context:\n",
        "              if self.relatedness_conceptnet(self.searching_objet, df['value_name'][i]) > 0.1:\n",
        "                relatedness = self.find_hitsnumber( df['value_name'][i])\n",
        "              else:\n",
        "                relatedness = 0\n",
        "                \n",
        "            else:\n",
        "                relatedness = 0\n",
        "            relatednesses.append({'relatedness': float(relatedness),\n",
        "                          'value':df['value_name'][i],\n",
        "                          'index':i})\n",
        "        temp_relatedness = pd.DataFrame(relatednesses)\n",
        "        sorted_relatedness = temp_relatedness.copy()\n",
        "        sorted_relatedness.sort_values(by='relatedness',inplace=True,ascending = False)\n",
        "        orders = list(range(len(temp_relatedness)))\n",
        "        for i in range(len(df)):\n",
        "            lllll[list(sorted_relatedness['index'])[i]] =  math.log(orders[i]+1,2)+ math.log(df['cnt'][i],2)    \n",
        "\n",
        "        for i in range(len(df)):\n",
        "            if df['value_name'][i] in context:\n",
        "                temp_com = math.log(len(context) - np.argwhere(contexte == df['value_name'][i])[0][0])\n",
        "                lllll[i] = min(temp_com, lllll[i])\n",
        "        return lllll, df\n",
        "    \n",
        "    def calculate_complexity_22(self, context):\n",
        "        '''\n",
        "        Get complexity of incoming properties\n",
        "        ------------\n",
        "        input: context (list)\n",
        "        ------------\n",
        "        output: complexity (list), data\n",
        "        \n",
        "        '''\n",
        "        df1 = self.wikidata_query(True)\n",
        "        #print(df1)\n",
        "        dropped = []\n",
        "        no_use = ['death place', 'birth place', 'home location', 'Metro','tram','station','Station','rue','Rue']\n",
        "        for item in no_use:\n",
        "            try:\n",
        "                dropped += [i for i,v in enumerate(list(df1['property_name'])) if v==item]\n",
        "                dropped += [i for i,v in enumerate(list(df1['un_name'])) if item in v]\n",
        "            except:\n",
        "                pass\n",
        "        df2 = df1.drop(dropped)\n",
        "        df = df2.sample(n = min(20,len(df2)), random_state = None)\n",
        "        df.reset_index(drop=True, inplace=True)\n",
        "        complexity_value = []\n",
        "        relatednesses = []\n",
        "        contexte = np.array(context)\n",
        "        lllll = np.zeros(len(df))\n",
        "        \n",
        "        for i in range(len(df)):\n",
        "            if df['un_name'][i] not in context:\n",
        "              #Because sometimes the incomming properties could be very general, like metro line 4, line 9\n",
        "              #So we limit the corresponding properties should at least have link with demanded city\n",
        "              if self.relatedness_conceptnet(self.searching_objet, df['un_name'][i]) > 0.1:\n",
        "                relatedness = self.find_hitsnumber( df['un_name'][i])\n",
        "              else:\n",
        "                relatedness = 0\n",
        "                \n",
        "            else:\n",
        "                relatedness = 0\n",
        "            relatednesses.append({'relatedness': float(relatedness),\n",
        "                          'value':df['un_name'][i],\n",
        "                          'index':i})\n",
        "        temp_relatedness = pd.DataFrame(relatednesses)\n",
        "        sorted_relatedness = temp_relatedness.copy()\n",
        "        sorted_relatedness.sort_values(by='relatedness',inplace=True,ascending = False)\n",
        "        orders = list(range(len(temp_relatedness)))\n",
        "        for i in range(len(df)):\n",
        "            lllll[list(sorted_relatedness['index'])[i]] =  math.log(orders[i]+1,2)    \n",
        "\n",
        "        for i in range(len(df)):\n",
        "            if df['un_name'][i] in context:\n",
        "                temp_com= math.log(len(context) - np.argwhere(contexte == df['un_name'][i])[0][0])\n",
        "                lllll[i] = min(temp_com, lllll[i])\n",
        "                #lllll[i] = 0\n",
        "        return lllll, df\n",
        "\n",
        "    \n",
        "    '''\n",
        "    Function to generate descriptions based on complexity\n",
        "    '''\n",
        "    def DescriptionByComplexity(self,number,context):\n",
        "        complexity, datas = self.calculate_complexity_1(context)\n",
        "        #datas = self.wikidata_query()\n",
        "        if len(datas) == 0:\n",
        "            print('No enough data')\n",
        "            return 'False', 'False'\n",
        "        descriptions = []\n",
        "        valeurs = []\n",
        "        #complexities = []\n",
        "        temp = np.array(complexity)\n",
        "        large_number = temp.argsort()[::1]\n",
        "        for i in range(len(large_number)):\n",
        "            prop = datas['property_name'][large_number[i]]\n",
        "            valeur = datas['value_name'][large_number[i]]\n",
        "            pertinence = temp[large_number[i]]\n",
        "            description = self.searching_objet + '----'+str(prop)+'---->'+str(valeur)+'   with complexity '+str(pertinence)\n",
        "            descriptions.append(description)\n",
        "            valeurs.append(valeur)\n",
        "        return descriptions[:number], valeurs[:number]\n",
        "    \n",
        "    def DescriptionByComplexity_inverse2(self,number,context):\n",
        "        complexity, datas = self.calculate_complexity_22(context)\n",
        "        #datas = self.wikidata_query()\n",
        "        descriptions = []\n",
        "        valeurs = []\n",
        "        temp = np.array(complexity)\n",
        "        large_number = temp.argsort()[::1]\n",
        "        for i in range(len(large_number)):\n",
        "            prop = datas['property_name'][large_number[i]]\n",
        "            valeur = datas['un_name'][large_number[i]]\n",
        "            pertinence = temp[large_number[i]]\n",
        "            description = self.searching_objet + '----'+str(prop)+'---->'+str(valeur)+'   with complexity '+str(pertinence)\n",
        "            descriptions.append(description)\n",
        "            valeurs.append(valeur)\n",
        "        return descriptions[:number], valeurs[:number]\n",
        "\n",
        "\n",
        "    '''\n",
        "    Three functions for generating descriptions with quantitative properties\n",
        "    ''' \n",
        "    def get_order(self,attribu, data, article):\n",
        "        \"\"\"\n",
        "        Input: 1. attribu: Features that users want to sort, str\n",
        "               2. data: DataFrame that contains all the information, DataFrame\n",
        "               3. article: City that users want to find the ranking\n",
        "        Output: order: City's ranking with respect to chosen feature\n",
        "        \"\"\"\n",
        "        temp = data.copy()\n",
        "        # To find which column stores the names\n",
        "        name_column = temp.columns.values.tolist().index('itemLabel')\n",
        "        # When given a feature, sort the datas\n",
        "        temp.sort_values(by=attribu,inplace=True,ascending = False)\n",
        "        order = np.argwhere(temp.values[:,name_column]==article)[0][0]+1\n",
        "        return order\n",
        "\n",
        "    def intersting_property(self, attribus):\n",
        "        '''\n",
        "        Input: attribus: all the features that the user want to take into consideration\n",
        "        Output: Corresponding descriptions\n",
        "        '''\n",
        "        data = self.wiki_contrast()\n",
        "        orders = []\n",
        "        complexities = []\n",
        "        items = []\n",
        "        for item in attribus:\n",
        "            if item != 'itemLabel':\n",
        "              ranking = self.get_order(item, data, self.searching_objet)\n",
        "              orders.append(ranking)\n",
        "              # Population ranks 716, area ranks 296 and altitude ranks 6915 for words frequency\n",
        "              if item == 'population':\n",
        "                complexities.append(math.log(ranking,2) + math.log(716,2))\n",
        "              elif item == 'sea_level':\n",
        "                complexities.append(math.log(ranking,2) + math.log(6915,2))\n",
        "              else:\n",
        "                complexities.append(math.log(ranking,2) + math.log(296,2))\n",
        "              items.append(item)\n",
        "        complexity = min(complexities)\n",
        "        order = min(orders)\n",
        "         # The smallest ranking is the most interesting for human beings\n",
        "        #order_index = orders.index(min(orders))\n",
        "        order_index = complexities.index(min(complexities))\n",
        "        name_column = data.columns.values.tolist().index('itemLabel')\n",
        "        place = np.argwhere(data.values[:,name_column]==self.searching_objet)[0][0]\n",
        "        description = str(data['itemdesc'][place])\n",
        "\n",
        "        descrption = self.searching_objet+''' is the city who has the '''+ str(orders[order_index])+'''th largest '''+items[order_index]+ ''' among the world'''\n",
        "        #print()\n",
        "        return description, descrption\n",
        "    \n",
        "    def __str__(self):\n",
        "        a = self.searching_objet\n",
        "        b = self.query\n",
        "        c = self.inverse_query\n",
        "        d = self.endpoint\n",
        "        return \"The searching object is \"+a+\", the query is \"+b+\", the inverse query is \"+c+\" and the endpoint is \"+d\n",
        "    \n",
        "\n",
        "\n",
        "class Yago(SparQL):\n",
        "    '''\n",
        "    This class is used to build an interface to visit Yago\n",
        "    '''\n",
        "    language = ''\n",
        "    searching_objet = ''\n",
        "    query = ''\n",
        "    inverse_query = ''\n",
        "    endpoint = yago_site\n",
        "    context = []\n",
        "    \n",
        "    def __init__(self, searchobjet, language):\n",
        "        self.language = language\n",
        "        self.searching_objet = searchobjet\n",
        "        self.query = yago_code_part1 + self.searching_objet + yago_code_part2\n",
        "        self.inverse_query = yago_inversecode_part1 + self.searching_objet + yago_inversecode_part2\n",
        "        #self.query = constant.yago_query_country\n",
        "\n",
        "\n",
        "class Pertinent_Description():\n",
        "  context = []\n",
        "\n",
        "  def __init__(self):\n",
        "    #a = input()\n",
        "    self.context = []\n",
        "\n",
        "  def Get_description(self, searching_object, language):\n",
        "    searching = re.sub('_',' ',searching_object)\n",
        "    y = Yago(searching_object,language)\n",
        "    Descriptions,items = y.DescriptionByComplexity(5,self.context)\n",
        "    Descriptions_in, items_in = y.DescriptionByComplexity_inverse2(5,self.context)\n",
        "    \n",
        "    w = Wikidata(searching_object)\n",
        "    Contrast_description = w.intersting_property(['population','sea_level','area'])\n",
        "    if Descriptions == 'False':\n",
        "        return Descriptions_in, Contrast_description\n",
        "    for item in items:\n",
        "        if item not in self.context:\n",
        "            self.context.append(item)\n",
        "    for item_in in items_in:\n",
        "        if item_in not in self.context:\n",
        "            self.context.append(item_in)\n",
        "    self.context.append(searching)\n",
        "    return Descriptions, Descriptions_in, Contrast_description\n",
        "    #return Descriptions_in\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "class Wikidata(SparQL):\n",
        "    searching_objet = ''\n",
        "    endpoint = wikidata_query_site\n",
        "    query = ''\n",
        "\n",
        "    \n",
        "    def __init__(self, searching_objet):\n",
        "        self.searching_objet = searching_objet\n",
        "        self.query = wikidata_query_city\n",
        "    '''    \n",
        "    def data_range(self):\n",
        "        data = self.wikidata_query()\n",
        "        return data\n",
        "    '''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnEMpTu1iWFz"
      },
      "source": [
        "# instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxA7NG1CiUC7"
      },
      "source": [
        "Please just press on the \"running button\" at the very beginning of each block. If you want to search for some other cities, for example: Beijing, just use the line:\n",
        "\n",
        "l.Get_description('Beijing','cn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gm61MastvsP"
      },
      "source": [
        "## realization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlfN-LIPDMb2"
      },
      "source": [
        "l = Pertinent_Description()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TGqbOemDooU",
        "outputId": "bf45a4c1-3c8a-4046-ecfb-dccceb8951bf"
      },
      "source": [
        "l.Get_description('Nagqu','cn')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No enough data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Nagqu----contained in place---->Sog County   with complexity 0.0',\n",
              "  'Nagqu----contained in place---->Tanggula Mountains   with complexity 1.0',\n",
              "  'Nagqu----contained in place---->Amdo County   with complexity 1.5849625007211563',\n",
              "  'Nagqu----contained in place---->Nyima County   with complexity 2.0',\n",
              "  'Nagqu----location---->Battle of the Salween River   with complexity 2.321928094887362'],\n",
              " (\"City in Tibet, People's Republic of China\",\n",
              "  'Nagqu is the city who has the 4th largest area among the world'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EouPMevE7ctS",
        "outputId": "b881fe96-10dd-41c1-ad4f-58325b4c5045"
      },
      "source": [
        "l.Get_description('Chengdu','fr')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Chengdu----contained in place---->Sichuan   with complexity 10.161131882984307'],\n",
              " ['Chengdu----contained in place---->Chongzhou   with complexity 0.0',\n",
              "  'Chengdu----contained in place---->Chengdu Normal University, CDNU   with complexity 1.0',\n",
              "  'Chengdu----contained in place---->Line 5   with complexity 1.5849625007211563',\n",
              "  'Chengdu----contained in place---->Southwest Jiaotong University   with complexity 2.0',\n",
              "  'Chengdu----contained in place---->Qionglai City   with complexity 2.321928094887362'],\n",
              " ('the capital of Sichuan Province, China',\n",
              "  'Chengdu is the city who has the 21th largest population among the world'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KhlEHzmD1Yv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8c32cd-54e9-4832-847e-dcc165437e10"
      },
      "source": [
        "l.Get_description('Paris','cn')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Paris----contained in place---->Metropolis of Greater Paris   with complexity 4.700439718141093',\n",
              "  'Paris----award---->Companion of the Liberation   with complexity 6.491853096329675',\n",
              "  'Paris----award---->Croix de guerre 1914–1918   with complexity 6.714245517666123',\n",
              "  'Paris----location---->Metropolis of Greater Paris   with complexity 7.238404739325079',\n",
              "  'Paris----location---->Île-de-France   with complexity 11.366322214245816'],\n",
              " ['Paris----content location---->I Am not an Easy Man   with complexity 0.0',\n",
              "  'Paris----contained in place---->Hôtel de Monaco   with complexity 1.0',\n",
              "  'Paris----contained in place---->Belleville   with complexity 1.5849625007211563',\n",
              "  'Paris----location---->Stade Français   with complexity 2.0',\n",
              "  'Paris----location---->Sorbonne Universities   with complexity 2.321928094887362'],\n",
              " ('capital and largest city of France',\n",
              "  'Paris is the city who has the 261th largest population among the world'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hyreWWtdftF",
        "outputId": "1d0b7fa5-75c6-4524-e9a7-a106cd5c205e"
      },
      "source": [
        "l.Get_description('Shanghai','cn')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([\"Shanghai----contained in place---->People's Republic of China   with complexity 2.9444389791664403\"],\n",
              " ['Shanghai----contained in place---->Lianqi He   with complexity 0.0',\n",
              "  'Shanghai----location---->Shanghai Experimental School   with complexity 1.0',\n",
              "  'Shanghai----contained in place---->Beicao Hangdao   with complexity 1.5849625007211563',\n",
              "  'Shanghai----contained in place---->Chongming District   with complexity 2.0',\n",
              "  'Shanghai----location---->Donghua University   with complexity 2.1972245773362196'],\n",
              " ('municipality of China',\n",
              "  'Shanghai is the city who has the 2th largest population among the world'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptmC0NGNfjRz",
        "outputId": "444341cf-179b-4acb-a8e9-a5844cdea4d5"
      },
      "source": [
        "l.Get_description('Lille','cn')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Lille----contained in place---->canton of Lille-4   with complexity 3.321928094887362',\n",
              "  'Lille----location---->arrondissement of Lille   with complexity 4.321928094887362',\n",
              "  'Lille----contained in place---->canton of Lille-Nord-Est   with complexity 4.584962500721156',\n",
              "  'Lille----contained in place---->arrondissement of Lille   with complexity 4.643856189774724',\n",
              "  'Lille----location---->canton of Lille-3   with complexity 4.807354922057604'],\n",
              " ['Lille----contained in place---->Institut Régional d’Administration de Lille   with complexity 0.0',\n",
              "  'Lille----contained in place---->Église Saint-Sauveur de Lille   with complexity 1.0',\n",
              "  'Lille----location---->Lycée International Montebello   with complexity 1.5849625007211563',\n",
              "  'Lille----contained in place---->Le Prato   with complexity 2.0',\n",
              "  'Lille----location---->Feast of the Pheasant   with complexity 2.321928094887362'],\n",
              " ('commune in Nord, France',\n",
              "  'Lille is the city who has the 1665th largest population among the world'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG5wz2hzd36D",
        "outputId": "534fd857-9803-487f-bd8c-1c162c014572"
      },
      "source": [
        "l.Get_description('Kunming','fr')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Kunming----contained in place---->Yunnan   with complexity 8.113742166049189'],\n",
              " ['Kunming----contained in place---->Xundian Hui and Yi Autonomous County   with complexity 0.0',\n",
              "  'Kunming----contains place---->Yunnan   with complexity 1.0',\n",
              "  'Kunming----location---->Yunnan University of Finance and Economics   with complexity 1.5849625007211563',\n",
              "  'Kunming----contained in place---->Yunnan Normal University Business School   with complexity 2.0',\n",
              "  'Kunming----location---->Kunming Tuodong Sports Center   with complexity 2.321928094887362'],\n",
              " ('Capital of Yunnan province, China',\n",
              "  'Kunming is the city who has the 108th largest area among the world'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFJysSF-lVv6",
        "outputId": "e64cf616-8ca7-4071-a4bc-5347b4dddcbf"
      },
      "source": [
        "l.Get_description('Paris','cn')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Paris----award---->Legion of Honour   with complexity 3.6635616461296463',\n",
              "  'Paris----location---->Metropolis of Greater Paris   with complexity 4.700439718141093',\n",
              "  'Paris----award---->Croix de guerre 1914–1918   with complexity 6.714245517666123',\n",
              "  'Paris----contained in place---->Metropolis of Greater Paris   with complexity 7.238404739325079',\n",
              "  'Paris----contained in place---->Île-de-France   with complexity 10.951284714966972'],\n",
              " ['Paris----content location---->Bel Ami   with complexity 0.0',\n",
              "  'Paris----location---->Hôtel George-V   with complexity 1.0',\n",
              "  'Paris----content location---->Danton   with complexity 1.5849625007211563',\n",
              "  'Paris----location---->Théâtre du Soleil   with complexity 2.0',\n",
              "  'Paris----location---->École de guerre   with complexity 2.321928094887362'],\n",
              " ('capital and largest city of France',\n",
              "  'Paris is the city who has the 261th largest population among the world'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQRPI5aWyXec"
      },
      "source": [
        "l.Get_description('Lyon','cn')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}